{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def remove_accents(text):\n",
    "    #Polish letters\n",
    "    letters= {\n",
    "    'ł':'l', 'ą':'a', 'ń':'n', 'ć':'c', 'ó':'o', 'ę':'e', 'ś':'s', 'ź':'z', 'ż':'z',\n",
    "    'Ł':'L', 'Ą':'A', 'Ń':'N', 'Ć':'C', 'Ó':'O', 'Ę':'E', 'Ś':'S', 'Ź':'Z', 'Ż':'Z',\n",
    "\n",
    "    #Accent Vowels\n",
    "    \"à\":\"a\", \"á\":\"a\", \"â\":\"a\", \"ã\":\"a\", \"ä\":\"a\", \"å\":\"a\", \"æ\": \"ae\",\n",
    "    \"À\":\"A\", \"Á\":\"A\", \"Â\":\"A\", \"Ã\":\"A\", \"Ä\":\"A\", \"Å\":\"A\", \"Æ\": \"ae\",\n",
    "\n",
    "    \"è\":\"e\", \"é\":\"e\", \"ê\":\"e\", \"ë\":\"e\",\n",
    "    \"È\":\"E\", \"É\":\"E\", \"Ê\":\"E\", \"Ë\":\"E\",\n",
    "\n",
    "    \"ì\":\"i\", \"í\":\"i\", \"î\":\"i\", \"ï\":\"i\",\n",
    "    \"Ì\":\"I\", \"Í\":\"I\", \"Î\":\"I\", \"Ï\":\"I\",\n",
    "\n",
    "    \"ò\": \"o\", \"ó\": \"o\", \"ô\": \"o\",  \"õ\": \"o\",  \"ö\": \"o\", \"ø\": \"o\",\n",
    "    \"Ò\": \"O\", \"Ó\": \"O\", \"Ô\": \"O\",  \"Õ\": \"O\",  \"Ö\": \"O\", \"Ø\": \"O\",\n",
    "\n",
    "    \"ù\": \"u\", \"ú\": \"u\",  \"û\": \"u\",  \"ü\": \"u\",\n",
    "    \"Ù\": \"U\", \"Ú\": \"U\",  \"Û\": \"U\",  \"Ü\": \"U\",\n",
    "\n",
    "    \"ý\": \"y\", \"ÿ\": \"y\",\n",
    "    \"Ý\": \"Y\", \"Ÿ\": \"Y\",\n",
    "\n",
    "    #Accent Cononants\n",
    "    \"ç\": \"c\", \"Ç\": \"C\",\n",
    "    \"ß\": \"ss\"\n",
    "    }\n",
    "    trans=str.maketrans(letters)\n",
    "    result=text.translate(trans)\n",
    "    return (result)\n",
    "\n",
    "def restructure_text(text):\n",
    "    while \"\\n\\n\" in text:\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "    text = text.replace(\"-\\n\", \"\").replace(\"- \", \"\")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    while \"  \" in text:\n",
    "        text = text.replace(\"  \", \" \")\n",
    "    return (text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_file, output_file, output_text_file):\n",
    "    with open (text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    text = remove_accents(text)\n",
    "    text = restructure_text(text)\n",
    "    nlp = English()\n",
    "    nlp.max_length = 100000000\n",
    "    nlp.add_pipe('sentencizer')\n",
    "    doc = nlp(text, disable=['parser', 'tagger', 'ner'])\n",
    "    all_sents = []\n",
    "    for sent in doc.sents:\n",
    "        sent = sent.text\n",
    "        sent = sent.strip()\n",
    "        all_sents.append(sent)\n",
    "    write_data(output_file, all_sents)\n",
    "    with open (output_text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in all_sents:\n",
    "            f.write(line+\"\\n\")\n",
    "    print (f\"File {text_file} complete.\")\n",
    "    print (f\"Total Sentences {len(all_sents)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(\"data/83468.txt\", \"data/83468.json\", \"data/sentences.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
